{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daytype2number(x):\n",
    "    return {\n",
    "        'normal': 0,\n",
    "        'partial': 1,\n",
    "        'off': 2,\n",
    "    }[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-5-ed7244dbeb2b>, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-ed7244dbeb2b>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    print subj,\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, time\n",
    "\n",
    "data_dir = '../../../Data/depression2016/CS120/'\n",
    "subjects = os.listdir(data_dir)\n",
    "# subjects = subjects[:2]\n",
    "\n",
    "timezones = pd.read_csv('../CS120/general/timezones.csv',sep='\\t',header=None)\n",
    "ind_nan = np.where(np.isnan(timezones[1]))[0]\n",
    "timezones.loc[ind_nan,1]=0\n",
    "\n",
    "acts = []\n",
    "emas = []\n",
    "emss = []\n",
    "\n",
    "for subj in subjects:\n",
    "    \n",
    "    print subj,\n",
    "    \n",
    "    act = pd.DataFrame(columns=['date','act'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/act.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/act.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+ 3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        act['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(act['date']):\n",
    "             act.loc[i,'act'] = np.sum(data.loc[data[0]==da,1]=='BIKING')+np.sum(data.loc[data[0]==da,1]=='ON_FOOT')\n",
    "    else:\n",
    "        print ' no act data'\n",
    "    acts.append(act)\n",
    "\n",
    "    ema = pd.DataFrame(columns=['date','stress','mood','energy','focus'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/emm.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/emm.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+ 3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        ema['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(ema['date']):\n",
    "            ema.loc[i,'stress'] = np.nanmean(data.loc[data[0]==da,1])\n",
    "            moods = data.loc[data[0]==da,2]\n",
    "            ema.loc[i,'mood'] = np.nanmean(moods)\n",
    "            ema.loc[i,'energy'] = np.nanmean(data.loc[data[0]==da,3])\n",
    "            ema.loc[i,'focus'] = np.nanmean(data.loc[data[0]==da,4])\n",
    "    else:\n",
    "        print ' no ema data'\n",
    "    emas.append(ema)\n",
    "        \n",
    "    ems = pd.DataFrame(columns=['date','duration','quality','daytype'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/ems.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/ems.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[3]/1000.0+3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        ems['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(ems['date']):\n",
    "            ems.loc[i,'duration'] = np.nanmean(data.loc[data[0]==da,3]-data.loc[data[0]==da,2])/1000.0\n",
    "            qual = np.array(data.loc[data[0]==da,5])\n",
    "            # if multiple entries, only take the first one\n",
    "            if qual.size>1:\n",
    "                ems.loc[i,'quality'] = qual[0]\n",
    "            else:\n",
    "                ems.loc[i,'quality'] = np.nanmean(qual)\n",
    "            daytype = data.loc[data[0]==da,6]\n",
    "            if daytype.size>0:\n",
    "                ems.loc[i,'daytype'] = daytype2number(daytype.values[0])\n",
    "            else:\n",
    "                ems.loc[i,'daytype'] = np.nan\n",
    "    else:\n",
    "        print ' no ems data'\n",
    "    emss.append(ems)\n",
    "\n",
    "# aligning the data\n",
    "data = []\n",
    "for (i,_) in enumerate(subjects):\n",
    "    \n",
    "    a = pd.merge(emas[i],emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    \n",
    "    # delayed (-1)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    acts[i]['date'] += 1\n",
    "    emas[i].columns = ['date','stress_prev','mood_prev','energy_prev','focus_prev']\n",
    "    emss[i].columns = ['date','duration_prev','quality_prev','daytype_prev']\n",
    "    acts[i].columns = ['date','act_prev']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    \n",
    "    # removing extra columns\n",
    "    emss[i] = emss[i].drop(['duration_prev','daytype_prev'], axis=1)\n",
    "    \n",
    "    # delayed (-2)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    acts[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev2','stress_prev2','energy_prev2','focus_prev2']\n",
    "    emss[i].columns = ['date','quality_prev2']\n",
    "    acts[i].columns = ['date','act_prev2']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    \n",
    "    # removing extra columns\n",
    "    emas[i] = emas[i].drop(['stress_prev2','energy_prev2','focus_prev2'], axis=1)\n",
    "    \n",
    "    # delayed (-3)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev3']\n",
    "    emss[i].columns = ['date','quality_prev3']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "\n",
    "    # delayed (-4) - for mood only\n",
    "    emas[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev4']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    \n",
    "    data.append(a)\n",
    "    \n",
    "with open('data.dat','w') as f:\n",
    "    pickle.dump([data, subjects], f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
