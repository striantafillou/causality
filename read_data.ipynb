{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daytype2number(x):\n",
    "    return {\n",
    "        'normal': 0,\n",
    "        'partial': 1,\n",
    "        'off': 2,\n",
    "    }[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EW057EV MQ077WG 1203725 BD921DW 1573207  no act data\n",
      "1578395 1464458 1135515 1183252 1521517 1210517 FM387DI 952207 1142152 984221 1553373 1244644  no act data\n",
      "1327952 1524496 1559190 1130955 1535103 1381257 1041667 1055808 1483186 1054952 1197009 1385032 IK750RN IP417XX 1564420 1288818 1571376 1567871 1328568 1374066 EW057DI  no act data\n",
      " no ema data\n",
      " no ems data\n",
      "1536580 XF600QF 1208813 1114936 1165040  no act data\n",
      "25349 1234088 827285 FJ227MJ 1124659 1422927 1270329 1219403 345921 1367477 1505268 1579481 HH880DL HE593LT WT253RB 606449 UQ050PR 1549226 1312819 428255  no act data\n",
      "1013558 1425272 1428949  no act data\n",
      "1524947 1533327 1305690 1084240 831987 1079411 1496251 1078563  no act data\n",
      "872451 QC647KS  no act data\n",
      "249499 828778 1143410 506107  no act data\n",
      "616751 1569370 1503395 1388630 1145713 1497026 1444502 820387 1097633 1128660  no act data\n",
      "1147164 856513  no act data\n",
      "1041304 1307868 1189725 920558 62977 1355344  no act data\n",
      "575209 1179075 IQ300QN 1272711 1184498 DB233EI 1022235 1299151  no act data\n",
      "871322 1560722 433874  no act data\n",
      "1557966 906629 636646 1401878 489868 964685 1336140 1155329 1567198 560623 98384 TP903SN 1213494  no act data\n",
      "HU113HP 1051651 1495360 97397 1411525 CB832WW QE210HJ 1217425 1213535  no act data\n",
      "1057121 510909  no act data\n",
      "1370566 NJ280ID  no act data\n",
      "1537431 1213906 CP140WM 1130163 1294671 1569348 1002060 1225160 1328707 HI713WB 1150915 1170978 1255682 564447 1126979 1307899 1080326 765488 1027472 1164303 JK130XR 662410 AC363GY QG620BT 1334243 JS253NF 1439160 733021 411896 1495049 1560782 1523880 1126438 SP157RF 555220 BJ540PT 1515656 639010 1380734 391378 1382086  no act data\n",
      "1531633 NQ003SV 1207041 1565499 JB320SW 1403756 919141 1550259 106743 1177977 39468 1199841 913164 1178484 1148714 1479464 1553904 630742 1401811 1433908 1157796 1229114  no act data\n",
      "XU620RL 1407619 1409046 1056017 1230637 38880 1061128 CL263NI 1186533 619634\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, time\n",
    "\n",
    "data_dir = '/data/CS120/'\n",
    "subjects = os.listdir(data_dir)\n",
    "# subjects = subjects[:2]\n",
    "\n",
    "timezones = pd.read_csv('../CS120/general/timezones.csv',sep='\\t',header=None)\n",
    "ind_nan = np.where(np.isnan(timezones[1]))[0]\n",
    "timezones.loc[ind_nan,1]=0\n",
    "\n",
    "acts = []\n",
    "emas = []\n",
    "emss = []\n",
    "\n",
    "for subj in subjects:\n",
    "    \n",
    "    print subj,\n",
    "    \n",
    "    act = pd.DataFrame(columns=['date','act'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/act.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/act.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+ 3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        act['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(act['date']):\n",
    "             act.loc[i,'act'] = np.sum(data.loc[data[0]==da,1]=='BIKING')+np.sum(data.loc[data[0]==da,1]=='ON_FOOT')\n",
    "    else:\n",
    "        print ' no act data'\n",
    "    acts.append(act)\n",
    "\n",
    "    ema = pd.DataFrame(columns=['date','stress','mood','energy','focus'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/emm.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/emm.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+ 3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        ema['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(ema['date']):\n",
    "            ema.loc[i,'stress'] = np.nanmean(data.loc[data[0]==da,1])\n",
    "            moods = data.loc[data[0]==da,2]\n",
    "            ema.loc[i,'mood'] = np.nanmean(moods)\n",
    "            ema.loc[i,'energy'] = np.nanmean(data.loc[data[0]==da,3])\n",
    "            ema.loc[i,'focus'] = np.nanmean(data.loc[data[0]==da,4])\n",
    "    else:\n",
    "        print ' no ema data'\n",
    "    emas.append(ema)\n",
    "        \n",
    "    ems = pd.DataFrame(columns=['date','duration','quality','daytype'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/ems.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/ems.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[3]/1000.0+3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        ems['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(ems['date']):\n",
    "            ems.loc[i,'duration'] = np.nanmean(data.loc[data[0]==da,3]-data.loc[data[0]==da,2])/1000.0\n",
    "            qual = np.array(data.loc[data[0]==da,5])\n",
    "            # if multiple entries, only take the first one\n",
    "            if qual.size>1:\n",
    "                ems.loc[i,'quality'] = qual[0]\n",
    "            else:\n",
    "                ems.loc[i,'quality'] = np.nanmean(qual)\n",
    "            daytype = data.loc[data[0]==da,6]\n",
    "            if daytype.size>0:\n",
    "                ems.loc[i,'daytype'] = daytype2number(daytype.values[0])\n",
    "            else:\n",
    "                ems.loc[i,'daytype'] = np.nan\n",
    "    else:\n",
    "        print ' no ems data'\n",
    "    emss.append(ems)\n",
    "\n",
    "# aligning the data\n",
    "data = []\n",
    "for (i,_) in enumerate(subjects):\n",
    "    \n",
    "    a = pd.merge(emas[i],emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    \n",
    "    # delayed (-1)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    acts[i]['date'] += 1\n",
    "    emas[i].columns = ['date','stress_prev','mood_prev','energy_prev','focus_prev']\n",
    "    emss[i].columns = ['date','duration_prev','quality_prev','daytype_prev']\n",
    "    acts[i].columns = ['date','act_prev']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    \n",
    "    # removing extra columns\n",
    "    emss[i] = emss[i].drop(['duration_prev','daytype_prev'], axis=1)\n",
    "    \n",
    "    # delayed (-2)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    acts[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev2','stress_prev2','energy_prev2','focus_prev2']\n",
    "    emss[i].columns = ['date','quality_prev2']\n",
    "    acts[i].columns = ['date','act_prev2']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    \n",
    "    # removing extra columns\n",
    "    emas[i] = emas[i].drop(['stress_prev2','energy_prev2','focus_prev2'], axis=1)\n",
    "    \n",
    "    # delayed (-3)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev3']\n",
    "    emss[i].columns = ['date','quality_prev3']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "\n",
    "    # delayed (-4) - for mood only\n",
    "    emas[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev4']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    \n",
    "    data.append(a)\n",
    "    \n",
    "with open('data.dat','w') as f:\n",
    "    pickle.dump([data, subjects], f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
