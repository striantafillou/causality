{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daytype2number(x):\n",
    "    return {\n",
    "        'normal': 0,\n",
    "        'partial': 1,\n",
    "        'off': 2,\n",
    "    }[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, time\n",
    "\n",
    "# data_dir ='/data/CS120/'\n",
    "# weather_dir ='/data/CS120Weather/'\n",
    "# csv_file = '../CS120/general/timezones.csv'\n",
    "# data_dir = '../../../Data/depression2016/CS120Data/CS120/'\n",
    "# csv_file = '../../../Data/depression2016/CS120Data/timezones.csv'\n",
    "# weather_dir ='../../../Data/depression2016/CS120Weather/'\n",
    "data_dir ='/home/sohrob/Dropbox/Data/CS120/'\n",
    "weather_dir ='/home/sohrob/Dropbox/Data/CS120Weather/'\n",
    "csv_file = '../CS120/general/timezones.csv'\n",
    "\n",
    "subjects = os.listdir(data_dir)\n",
    "subjects.remove('desktop.ini')\n",
    "# subjects.remove('.dropbox')\n",
    "\n",
    "timezones = pd.read_csv(csv_file,sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1002060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.4/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1013558\n",
      "2 1022235\n",
      "3 1027472\n",
      "4 1041304\n",
      "5 1041667\n",
      "6 1051651\n",
      "7 1054952\n",
      "8 1055808\n",
      "9 1056017\n",
      "10 1057121\n",
      "11 1061128\n",
      "12 106743\n",
      "13 1078563\n",
      " no act data\n",
      "14 1079411\n",
      "15 1080326\n",
      "16 1084240\n",
      "17 1097633\n",
      "18 1114936\n",
      "19 1124659\n",
      "20 1126438\n",
      "21 1126979\n",
      "22 1128660\n",
      " no act data\n",
      "23 1130163\n",
      "24 1130955\n",
      "25 1135515\n",
      "26 1142152\n",
      "27 1143410\n",
      "28 1145713\n",
      "29 1147164\n",
      "30 1148714\n",
      "31 1150915\n",
      "32 1155329\n",
      "33 1157796\n",
      "34 1164303\n",
      "35 1165040\n",
      " no act data\n",
      "36 1170978\n",
      "37 1177977\n",
      "38 1178484\n",
      "39 1179075\n",
      "40 1183252\n",
      "41 1184498\n",
      "42 1186533\n",
      "43 1189725\n",
      "44 1197009\n",
      "45 1199841\n",
      "46 1203725\n",
      "47 1207041\n",
      "48 1208813\n",
      "49 1210517\n",
      "50 1213494\n",
      " no act data\n",
      "51 1213535\n",
      " no act data\n",
      "52 1213906\n",
      "53 1217425\n",
      "54 1219403\n",
      "55 1225160\n",
      "56 1229114\n",
      " no act data\n",
      "57 1230637\n",
      "58 1234088\n",
      "59 1244644\n",
      " no act data\n",
      "60 1255682\n",
      "61 1270329\n",
      "62 1272711\n",
      "63 1288818\n",
      "64 1294671\n",
      "65 1299151\n",
      " no act data\n",
      "66 1305690\n",
      "67 1307868\n",
      "68 1307899\n",
      "69 1312819\n",
      "70 1327952\n",
      "71 1328568\n",
      "72 1328707\n",
      "73 1334243\n",
      "74 1336140\n",
      "75 1355344\n",
      " no act data\n",
      "76 1367477\n",
      "77 1370566\n",
      "78 1374066\n",
      "79 1380734\n",
      "80 1381257\n",
      "81 1382086\n",
      " no act data\n",
      "82 1385032\n",
      "83 1388630\n",
      "84 1401811\n",
      "85 1401878\n",
      "86 1403756\n",
      "87 1407619\n",
      "88 1409046\n",
      "89 1411525\n",
      "90 1422927\n",
      "91 1425272\n",
      "92 1428949\n",
      " no act data\n",
      "93 1433908\n",
      "94 1439160\n",
      "95 1444502\n",
      "96 1464458\n",
      "97 1479464\n",
      "98 1483186\n",
      "99 1495049\n",
      "100 1495360\n",
      "101 1496251\n",
      " no weather data\n",
      "102 1497026\n",
      "103 1503395\n",
      "104 1505268\n",
      "105 1515656\n",
      "subject skipped due to spoofed gps data\n",
      "106 1521517\n",
      "107 1523880\n",
      "108 1524496\n",
      "109 1524947\n",
      "110 1531633\n",
      "111 1533327\n",
      "112 1535103\n",
      "113 1536580\n",
      "114 1537431\n",
      "115 1549226\n",
      "116 1550259\n",
      "117 1553373\n",
      "118 1553904\n",
      "119 1557966\n",
      "120 1559190\n",
      "121 1560722\n",
      "122 1560782\n",
      "123 1564420\n",
      "124 1565499\n",
      "125 1567198\n",
      "126 1567871\n",
      "127 1569348\n",
      "128 1569370\n",
      "129 1571376\n",
      "130 1573207\n",
      " no act data\n",
      "131 1578395\n",
      "132 1579481\n",
      "133 249499\n",
      "134 25349\n",
      "135 345921\n",
      "136 38880\n",
      "137 391378\n",
      "138 39468\n",
      "139 411896\n",
      "140 428255\n",
      " no act data\n",
      "141 433874\n",
      " no act data\n",
      "142 489868\n",
      "143 506107\n",
      " no act data\n",
      "144 510909\n",
      " no act data\n",
      "145 555220\n",
      "146 560623\n",
      "147 564447\n",
      "148 575209\n",
      "149 606449\n",
      "150 616751\n",
      "151 619634\n",
      "152 62977\n",
      "153 630742\n",
      "154 636646\n",
      "155 639010\n",
      "156 662410\n",
      "157 733021\n",
      "158 765488\n",
      "159 820387\n",
      "160 827285\n",
      "161 828778\n",
      "162 831987\n",
      "163 856513\n",
      " no act data\n",
      "164 871322\n",
      "165 872451\n",
      "166 906629\n",
      "167 913164\n",
      " no weather data\n",
      "168 919141\n",
      "169 920558\n",
      "170 952207\n",
      "171 964685\n",
      "172 97397\n",
      "173 98384\n",
      "174 984221\n",
      "175 AC363GY\n",
      "176 BD921DW\n",
      "177 BJ540PT\n",
      "178 CB832WW\n",
      "179 CL263NI\n",
      "180 CP140WM\n",
      "181 DB233EI\n",
      "182 EW057DI\n",
      "subject skipped due to spoofed gps data\n",
      "183 EW057EV\n",
      "184 FJ227MJ\n",
      "185 FM387DI\n",
      " no weather data\n",
      "186 HE593LT\n",
      " no weather data\n",
      "187 HH880DL\n",
      "188 HI713WB\n",
      "189 HU113HP\n",
      "190 IK750RN\n",
      "191 IP417XX\n",
      "192 IQ300QN\n",
      "193 JB320SW\n",
      "194 JK130XR\n",
      "195 JS253NF\n",
      "196 MQ077WG\n",
      "197 NJ280ID\n",
      " no act data\n",
      "198 NQ003SV\n",
      "199 QC647KS\n",
      " no act data\n",
      "200 QE210HJ\n",
      "201 QG620BT\n",
      "202 SP157RF\n",
      "203 TP903SN\n",
      "204 UQ050PR\n",
      " no weather data\n",
      "205 WT253RB\n",
      "206 XF600QF\n",
      "207 XU620RL\n"
     ]
    }
   ],
   "source": [
    "# subjects = subjects[:2]\n",
    "\n",
    "ind_nan = np.where(np.isnan(timezones[1]))[0]\n",
    "timezones.loc[ind_nan,1]=0\n",
    "\n",
    "acts = []\n",
    "emas = []\n",
    "emss = []\n",
    "wtrs =[]\n",
    "subjects_edited = []\n",
    "\n",
    "for (cnt,subj) in enumerate(subjects):\n",
    "    \n",
    "    print(cnt,subj,)\n",
    "    \n",
    "    # 1515656 has bad GPS\n",
    "    # EW057DI has no self-report\n",
    "    if subj=='1515656' or subj=='EW057DI':\n",
    "        print('subject skipped due to spoofed gps data')\n",
    "        continue\n",
    "    \n",
    "    subjects_edited.append(subj)\n",
    "    \n",
    "    act = pd.DataFrame(columns=['date','act'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/act.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/act.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+ 3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        act['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(act['date']):\n",
    "             act.loc[i,'act'] = np.sum(data.loc[data[0]==da,1]=='BIKING')+np.sum(data.loc[data[0]==da,1]=='ON_FOOT')\n",
    "    else:\n",
    "        print(' no act data')\n",
    "    acts.append(act)\n",
    "\n",
    "    ema = pd.DataFrame(columns=['date','stress','mood','energy','focus'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/emm.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/emm.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+ 3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        ema['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(ema['date']):\n",
    "            ema.loc[i,'stress'] = np.nanmean(data.loc[data[0]==da,1])\n",
    "            moods = data.loc[data[0]==da,2]\n",
    "            ema.loc[i,'mood'] = np.nanmean(moods)\n",
    "            ema.loc[i,'energy'] = np.nanmean(data.loc[data[0]==da,3])\n",
    "            ema.loc[i,'focus'] = np.nanmean(data.loc[data[0]==da,4])\n",
    "    else:\n",
    "        print(' no ema data')\n",
    "    emas.append(ema)\n",
    "    \n",
    "    ems = pd.DataFrame(columns=['date','duration','quality','daytype'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/ems.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/ems.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[3]/1000.0+3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        ems['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(ems['date']):\n",
    "            ems.loc[i,'duration'] = np.nanmean(data.loc[data[0]==da,3]-data.loc[data[0]==da,2])/1000.0\n",
    "            qual = np.array(data.loc[data[0]==da,5])\n",
    "            # if multiple entries, only take the first one\n",
    "            if qual.size>1:\n",
    "                ems.loc[i,'quality'] = qual[0]\n",
    "            else:\n",
    "                ems.loc[i,'quality'] = np.nanmean(qual)\n",
    "            daytype = data.loc[data[0]==da,6]\n",
    "            if daytype.size>0:\n",
    "                ems.loc[i,'daytype'] = daytype2number(daytype.values[0])\n",
    "            else:\n",
    "                ems.loc[i,'daytype'] = np.nan\n",
    "    else:\n",
    "        print(' no ems data')\n",
    "    emss.append(ems)\n",
    "        \n",
    "    wtr = pd.DataFrame(columns=['date','mean_temp','clear'], dtype=float)\n",
    "    if os.path.exists(weather_dir+subj+'/wtr.csv') and  os.stat(weather_dir+subj+'/wtr.csv').st_size > 0:\n",
    "        data = pd.read_csv(weather_dir+subj+'/wtr.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        wtr['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(wtr['date']):\n",
    "            # wrt.loc[i,'duration'] = np.nanmean(data.loc[data[0]==da,1])/1000.0\n",
    "            tmptemp = np.array(data.loc[data[0]==da,1])\n",
    "            tmpclear = np.array(data.loc[data[0]==da, 9])\n",
    "\n",
    "            # take the mean of multiple entries\n",
    "            if tmptemp.size>0:\n",
    "                wtr.loc[i,'mean_temp'] = np.nanmean(tmptemp)\n",
    "                wtr.loc[i, 'clear'] = np.sum(tmpclear=='Clear');\n",
    "    else:\n",
    "        print(' no weather data')\n",
    "    wtrs.append(wtr)\n",
    "    \n",
    "subjects = subjects_edited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for (i,_) in enumerate(subjects):\n",
    "    \n",
    "    a = pd.merge(emas[i],emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    a = pd.merge(a,wtrs[i], on='date', how='outer')\n",
    "    \n",
    "    # delayed (-1)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    acts[i]['date'] += 1\n",
    "    wtrs[i]['date'] += 1\n",
    "    emas[i].columns = ['date','stress_prev','mood_prev','energy_prev','focus_prev']\n",
    "    emss[i].columns = ['date','duration_prev','quality_prev','daytype_prev']\n",
    "    acts[i].columns = ['date','act_prev']\n",
    "    wtrs[i].columns = ['date','mean_temp_prev', 'clear_prev']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    a = pd.merge(a,wtrs[i], on='date', how='outer')\n",
    "\n",
    "    # removing extra columns\n",
    "    emss[i] = emss[i].drop(['duration_prev','daytype_prev'], axis=1)\n",
    "    \n",
    "    # delayed (-2)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    acts[i]['date'] += 1\n",
    "    wtrs[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev2','stress_prev2','energy_prev2','focus_prev2']\n",
    "    emss[i].columns = ['date','quality_prev2']\n",
    "    acts[i].columns = ['date','act_prev2']\n",
    "    wtrs[i].columns = ['date','mean_temp_prev2', 'clear_prev2']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    a = pd.merge(a,wtrs[i],on='date',how='outer')\n",
    "\n",
    "    # removing extra columns\n",
    "    emas[i] = emas[i].drop(['stress_prev2','energy_prev2','focus_prev2'], axis=1)\n",
    "    \n",
    "    # delayed (-3)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev3']\n",
    "    emss[i].columns = ['date','quality_prev3']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "\n",
    "    # delayed (-4) - for mood only\n",
    "    emas[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev4']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    \n",
    "    data.append(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add day of the week and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import datetime as dt\n",
    "import calendar\n",
    "\n",
    "for (i,_) in enumerate(subjects):\n",
    "    ts =data[i].date*86400\n",
    "    #tmp =dt.datetime.fromtimestamp().day\n",
    "    data[i]['dow']=[dt.datetime.fromtimestamp(t).weekday() for t in ts]\n",
    "    \n",
    "with open('data.dat','wb') as f:\n",
    "    pickle.dump([data, subjects], f, protocol=2)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
