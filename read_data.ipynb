{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daytype2number(x):\n",
    "    return {\n",
    "        'normal': 0,\n",
    "        'partial': 1,\n",
    "        'off': 2,\n",
    "    }[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, time\n",
    "\n",
    "# sohrob on nu server\n",
    "# data_dir ='/data/CS120/'\n",
    "# weather_dir ='/data/CS120Weather/'\n",
    "# csv_file = '../CS120/general/timezones.csv'\n",
    "\n",
    "# sofia' s pc\n",
    "# data_dir = '../../../Data/depression2016/CS120Data/CS120/'\n",
    "# csv_file = '../../../Data/depression2016/CS120Data/timezones.csv'\n",
    "# weather_dir ='../../../Data/depression2016/CS120Weather/'\n",
    "\n",
    "# sohrob's pc\n",
    "# data_dir ='/home/sohrob/Dropbox/Data/CS120/'\n",
    "# weather_dir ='/home/sohrob/Dropbox/Data/CS120Weather/'\n",
    "# csv_file = '../CS120/general/timezones.csv'\n",
    "\n",
    "#subjects.remove('desktop.ini')\n",
    "# subjects.remove('.dropbox')\n",
    "#sofia on quadcorn\n",
    "data_dir = '../Data/depression2016/depression2016/CS120Data/CS120/'\n",
    "csv_file = '../Data/depression2016/depression2016/CS120Data/timezones.csv'\n",
    "weather_dir ='../Data/depression2016/depression2016/CS120Weather/'\n",
    "subjects = os.listdir(data_dir)\n",
    "\n",
    "\n",
    "timezones = pd.read_csv(csv_file,sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '..../Data/depression2016/depression2016/CS120/Assessment/assessment.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-eca35e5f88ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# read assessments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..../Data/depression2016/depression2016/CS120/Assessment/assessment.dat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '..../Data/depression2016/depression2016/CS120/Assessment/assessment.dat'"
     ]
    }
   ],
   "source": [
    "# read assessments\n",
    "with open('..../Data/depression2016/depression2016/CS120/Assessment/assessment.dat', 'rb') as f:\n",
    "    ass = pickle.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '1579481')\n",
      "(1, '1425272')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/opt/anaconda/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, '984221')\n",
      "(3, '1145713')\n",
      "(4, 'HE593LT')\n",
      " no weather data\n",
      "(5, '1564420')\n",
      "(6, '1521517')\n",
      "(7, 'FJ227MJ')\n",
      "(8, '1041667')\n",
      "(9, '1213535')\n",
      " no act data\n",
      "(10, '1255682')\n",
      "(11, '489868')\n",
      "(12, '1184498')\n",
      "(13, '1097633')\n",
      "(14, 'TP903SN')\n",
      "(15, 'QG620BT')\n",
      "(16, '1433908')\n",
      "(17, '555220')\n",
      "(18, 'BD921DW')\n",
      "(19, '1155329')\n",
      "(20, 'UQ050PR')\n",
      " no weather data\n",
      "(21, 'CB832WW')\n",
      "(22, '1503395')\n",
      "(23, '1367477')\n",
      "(24, '1229114')\n",
      " no act data\n",
      "(25, '919141')\n",
      "(26, '1294671')\n",
      "(27, 'JB320SW')\n",
      "(28, '913164')\n",
      " no weather data\n",
      "(29, '1374066')\n",
      "(30, 'WT253RB')\n",
      "(31, 'DB233EI')\n",
      "(32, '1560782')\n",
      "(33, '1569370')\n",
      "(34, 'SP157RF')\n",
      "(35, '1124659')\n",
      "(36, '1401811')\n",
      "(37, '1428949')\n",
      " no act data\n",
      "(38, '1126438')\n",
      "(39, '1128660')\n",
      " no act data\n",
      "(40, '564447')\n",
      "(41, '1288818')\n",
      "(42, '1157796')\n",
      "(43, '1307868')\n",
      "(44, '1078563')\n",
      " no act data\n",
      "(45, 'CL263NI')\n",
      "(46, '39468')\n",
      "(47, '1199841')\n",
      "(48, '1327952')\n",
      "(49, 'HU113HP')\n",
      "(50, 'BJ540PT')\n",
      "(51, '636646')\n",
      "(52, '97397')\n",
      "(53, '1495360')\n",
      "(54, '1569348')\n",
      "(55, '1479464')\n",
      "(56, '1299151')\n",
      " no act data\n",
      "(57, '1578395')\n",
      "(58, '1178484')\n",
      "(59, '1559190')\n",
      "(60, '1497026')\n",
      "(61, '575209')\n",
      "(62, '1567871')\n",
      "(63, '1219403')\n",
      "(64, '1208813')\n",
      "(65, '820387')\n",
      "(66, '1142152')\n",
      "(67, '1571376')\n",
      "(68, '1130955')\n",
      "(69, '1403756')\n",
      "(70, '1114936')\n",
      "(71, '1051651')\n",
      "(72, '1505268')\n",
      "(73, '1531633')\n",
      "(74, '1270329')\n",
      "(75, '1210517')\n",
      "(76, '1422927')\n",
      "(77, '98384')\n",
      "(78, '1197009')\n",
      "(79, '871322')\n",
      "(80, '1170978')\n",
      "(81, '1130163')\n",
      "(82, 'EW057EV')\n",
      "(83, '345921')\n",
      "(84, '662410')\n",
      "(85, '1550259')\n",
      "(86, 'NJ280ID')\n",
      " no act data\n",
      "(87, '1207041')\n",
      "(88, 'MQ077WG')\n",
      "(89, '1515656')\n",
      "subject skipped due to spoofed gps data\n",
      "(90, '1143410')\n",
      "(91, '1444502')\n",
      "(92, 'IQ300QN')\n",
      "(93, '1213494')\n",
      " no act data\n",
      "(94, 'XF600QF')\n",
      "(95, '1225160')\n",
      "(96, '1165040')\n",
      " no act data\n",
      "(97, 'AC363GY')\n",
      "(98, '1328707')\n",
      "(99, '1217425')\n",
      "(100, 'EW057DI')\n",
      "subject skipped due to spoofed gps data\n",
      "(101, '619634')\n",
      "(102, '1305690')\n",
      "(103, '1027472')\n",
      "(104, '606449')\n",
      "(105, '1307899')\n",
      "(106, '616751')\n",
      "(107, '1385032')\n",
      "(108, '1496251')\n",
      " no weather data\n",
      "(109, '1164303')\n",
      "(110, '1041304')\n",
      "(111, '1234088')\n",
      "(112, '1409046')\n",
      "(113, '1084240')\n",
      "(114, '506107')\n",
      " no act data\n",
      "(115, '1334243')\n",
      "(116, '1186533')\n",
      "(117, '411896')\n",
      "(118, '1022235')\n",
      "(119, '1079411')\n",
      "(120, '1055808')\n",
      "(121, '1179075')\n",
      "(122, '106743')\n",
      "(123, '1495049')\n",
      "(124, '1537431')\n",
      "(125, '831987')\n",
      "(126, '1439160')\n",
      "(127, '391378')\n",
      "(128, '1380734')\n",
      "(129, '1177977')\n",
      "(130, '1126979')\n",
      "(131, '872451')\n",
      "(132, 'IP417XX')\n",
      "(133, '765488')\n",
      "(134, '510909')\n",
      " no act data\n",
      "(135, '1535103')\n",
      "(136, '1056017')\n",
      "(137, '1381257')\n",
      "(138, 'IK750RN')\n",
      "(139, '1061128')\n",
      "(140, 'XU620RL')\n",
      "(141, '964685')\n",
      "(142, '1057121')\n",
      "(143, '1401878')\n",
      "(144, '827285')\n",
      "(145, 'JS253NF')\n",
      "(146, '1080326')\n",
      "(147, '1148714')\n",
      "(148, 'HH880DL')\n",
      "(149, '1533327')\n",
      "(150, '1054952')\n",
      "(151, '1013558')\n",
      "(152, '1150915')\n",
      "(153, 'JK130XR')\n",
      "(154, '639010')\n",
      "(155, '1464458')\n",
      "(156, '1553904')\n",
      "(157, 'FM387DI')\n",
      " no weather data\n",
      "(158, '1565499')\n",
      "(159, '1203725')\n",
      "(160, '1557966')\n",
      "(161, '1573207')\n",
      " no act data\n",
      "(162, '733021')\n",
      "(163, '62977')\n",
      "(164, '1312819')\n",
      "(165, '1411525')\n",
      "(166, 'QE210HJ')\n",
      "(167, '1147164')\n",
      "(168, '433874')\n",
      " no act data\n",
      "(169, '1244644')\n",
      " no act data\n",
      "(170, '1536580')\n",
      "(171, '920558')\n",
      "(172, '952207')\n",
      "(173, '828778')\n",
      "(174, '1407619')\n",
      "(175, '249499')\n",
      "(176, '1002060')\n",
      "(177, '38880')\n",
      "(178, '1189725')\n",
      "(179, '856513')\n",
      " no act data\n",
      "(180, '1553373')\n",
      "(181, 'NQ003SV')\n",
      "(182, '1336140')\n",
      "(183, '1272711')\n",
      "(184, '1382086')\n",
      " no act data\n",
      "(185, '1328568')\n",
      "(186, '1388630')\n",
      "(187, '1549226')\n",
      "(188, '1370566')\n",
      "(189, 'QC647KS')\n",
      " no act data\n",
      "(190, '1524496')\n",
      "(191, '25349')\n",
      "(192, '1560722')\n",
      "(193, 'HI713WB')\n",
      "(194, '1183252')\n",
      "(195, '906629')\n",
      "(196, 'CP140WM')\n",
      "(197, '1135515')\n",
      "(198, '1213906')\n",
      "(199, '560623')\n",
      "(200, '1230637')\n",
      "(201, '428255')\n",
      " no act data\n",
      "(202, '1483186')\n",
      "(203, '1567198')\n",
      "(204, '1523880')\n",
      "(205, '1524947')\n",
      "(206, '1355344')\n",
      " no act data\n",
      "(207, '630742')\n"
     ]
    }
   ],
   "source": [
    "# subjects = subjects[:2]\n",
    "\n",
    "ind_nan = np.where(np.isnan(timezones[1]))[0]\n",
    "timezones.loc[ind_nan,1]=0\n",
    "\n",
    "acts = []\n",
    "emas = []\n",
    "emss = []\n",
    "wtrs =[]\n",
    "subjects_edited = []\n",
    "\n",
    "for (cnt,subj) in enumerate(subjects):\n",
    "    \n",
    "    print(cnt,subj,)\n",
    "    \n",
    "    # 1515656 has bad GPS\n",
    "    # EW057DI has no self-report\n",
    "    if subj=='1515656' or subj=='EW057DI':\n",
    "        print('subject skipped due to spoofed gps data')\n",
    "        continue\n",
    "    \n",
    "    subjects_edited.append(subj)\n",
    "    \n",
    "    act = pd.DataFrame(columns=['date','act'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/act.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/act.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+ 3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        act['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(act['date']):\n",
    "             act.loc[i,'act'] = np.sum(data.loc[data[0]==da,1]=='BIKING')+np.sum(data.loc[data[0]==da,1]=='ON_FOOT')\n",
    "    else:\n",
    "        print(' no act data')\n",
    "    acts.append(act)\n",
    "\n",
    "    ema = pd.DataFrame(columns=['date','stress','mood','energy','focus'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/emm.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/emm.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+ 3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        ema['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(ema['date']):\n",
    "            ema.loc[i,'stress'] = np.nanmean(data.loc[data[0]==da,1])\n",
    "            moods = data.loc[data[0]==da,2]\n",
    "            ema.loc[i,'mood'] = np.nanmean(moods)\n",
    "            ema.loc[i,'energy'] = np.nanmean(data.loc[data[0]==da,3])\n",
    "            ema.loc[i,'focus'] = np.nanmean(data.loc[data[0]==da,4])\n",
    "    else:\n",
    "        print(' no ema data')\n",
    "    emas.append(ema)\n",
    "    \n",
    "    ems = pd.DataFrame(columns=['date','duration','quality','daytype'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/ems.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/ems.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[3]/1000.0+3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        ems['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(ems['date']):\n",
    "            ems.loc[i,'duration'] = np.nanmean(data.loc[data[0]==da,3]-data.loc[data[0]==da,2])/1000.0\n",
    "            qual = np.array(data.loc[data[0]==da,5])\n",
    "            # if multiple entries, only take the first one\n",
    "            if qual.size>1:\n",
    "                ems.loc[i,'quality'] = qual[0]\n",
    "            else:\n",
    "                ems.loc[i,'quality'] = np.nanmean(qual)\n",
    "            daytype = data.loc[data[0]==da,6]\n",
    "            if daytype.size>0:\n",
    "                ems.loc[i,'daytype'] = daytype2number(daytype.values[0])\n",
    "            else:\n",
    "                ems.loc[i,'daytype'] = np.nan\n",
    "    else:\n",
    "        print(' no ems data')\n",
    "    emss.append(ems)\n",
    "        \n",
    "    wtr = pd.DataFrame(columns=['date','mean_temp','clear'], dtype=float)\n",
    "    if os.path.exists(weather_dir+subj+'/wtr.csv') and  os.stat(weather_dir+subj+'/wtr.csv').st_size > 0:\n",
    "        data = pd.read_csv(weather_dir+subj+'/wtr.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        wtr['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(wtr['date']):\n",
    "            # wrt.loc[i,'duration'] = np.nanmean(data.loc[data[0]==da,1])/1000.0\n",
    "            tmptemp = np.array(data.loc[data[0]==da,1])\n",
    "            tmpclear = np.array(data.loc[data[0]==da, 9])\n",
    "\n",
    "            # take the mean of multiple entries\n",
    "            if tmptemp.size>0:\n",
    "                wtr.loc[i,'mean_temp'] = np.nanmean(tmptemp)\n",
    "                wtr.loc[i, 'clear'] = np.sum(tmpclear=='Clear');\n",
    "    else:\n",
    "        print(' no weather data')\n",
    "    wtrs.append(wtr)\n",
    "    \n",
    "subjects = subjects_edited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for (i,_) in enumerate(subjects):\n",
    "    \n",
    "    a = pd.merge(emas[i],emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    a = pd.merge(a,wtrs[i], on='date', how='outer')\n",
    "    \n",
    "    # delayed (-1)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    acts[i]['date'] += 1\n",
    "    wtrs[i]['date'] += 1\n",
    "    emas[i].columns = ['date','stress_prev','mood_prev','energy_prev','focus_prev']\n",
    "    emss[i].columns = ['date','duration_prev','quality_prev','daytype_prev']\n",
    "    acts[i].columns = ['date','act_prev']\n",
    "    wtrs[i].columns = ['date','mean_temp_prev', 'clear_prev']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    a = pd.merge(a,wtrs[i], on='date', how='outer')\n",
    "\n",
    "    # removing extra columns\n",
    "    emss[i] = emss[i].drop(['duration_prev','daytype_prev'], axis=1)\n",
    "    \n",
    "    # delayed (-2)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    acts[i]['date'] += 1\n",
    "    wtrs[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev2','stress_prev2','energy_prev2','focus_prev2']\n",
    "    emss[i].columns = ['date','quality_prev2']\n",
    "    acts[i].columns = ['date','act_prev2']\n",
    "    wtrs[i].columns = ['date','mean_temp_prev2', 'clear_prev2']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    a = pd.merge(a,wtrs[i],on='date',how='outer')\n",
    "\n",
    "    # removing extra columns\n",
    "    emas[i] = emas[i].drop(['stress_prev2','energy_prev2','focus_prev2'], axis=1)\n",
    "    \n",
    "    # delayed (-3)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev3']\n",
    "    emss[i].columns = ['date','quality_prev3']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "\n",
    "    # delayed (-4) - for mood only\n",
    "    emas[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev4']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    \n",
    "    data.append(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add day of the week and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import datetime as dt\n",
    "import calendar\n",
    "\n",
    "for (i,_) in enumerate(subjects):\n",
    "    ts =data[i].date*86400\n",
    "    #tmp =dt.datetime.fromtimestamp().day\n",
    "    data[i]['dow']=[dt.datetime.fromtimestamp(t).weekday() for t in ts]\n",
    "    \n",
    "with open('data.dat','wb') as f:\n",
    "    pickle.dump([data, subjects], f, protocol=2)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
