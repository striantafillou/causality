{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def daytype2number(x):\n",
    "    return {\n",
    "        'normal': 0,\n",
    "        'partial': 1,\n",
    "        'off': 2,\n",
    "    }[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime, time\n",
    "\n",
    "data_dir ='/data/CS120/'\n",
    "weather_dir ='/data/CS120Weather/'\n",
    "csv_file = '../CS120/general/timezones.csv'\n",
    "# data_dir = '../../../Data/depression2016/CS120Data/CS120/'\n",
    "# csv_file = '../../../Data/depression2016/CS120Data/timezones.csv'\n",
    "# weather_dir ='../../../Data/depression2016/CS120Weather/'\n",
    "\n",
    "subjects = os.listdir(data_dir)\n",
    "timezones = pd.read_csv(csv_file,sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 EW057EV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.4/dist-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MQ077WG\n",
      "2 1203725\n",
      "3 BD921DW\n",
      "4 1573207\n",
      " no act data\n",
      "5 1578395\n",
      "6 1464458\n",
      "7 1135515\n",
      "8 1183252\n",
      "9 1521517\n",
      "10 1210517\n",
      "11 FM387DI\n",
      " no weather data\n",
      "12 952207\n",
      "13 1142152\n",
      "14 984221\n",
      "15 1553373\n",
      "16 1244644\n",
      " no act data\n",
      "17 1327952\n",
      "18 1524496\n",
      "19 1559190\n",
      "20 1130955\n",
      "21 1535103\n",
      "22 1381257\n",
      "23 1041667\n",
      "24 1055808\n",
      "25 1483186\n",
      "26 1054952\n",
      "27 1197009\n",
      "28 1385032\n",
      "29 IK750RN\n",
      "30 IP417XX\n",
      "31 1564420\n",
      "32 1288818\n",
      "33 1571376\n",
      "34 1567871\n",
      "35 1328568\n",
      "36 1374066\n",
      "37 EW057DI\n",
      " no act data\n",
      " no ema data\n",
      " no ems data\n",
      " no weather data\n",
      "38 1536580\n",
      "39 XF600QF\n",
      "40 1208813\n",
      "41 1114936\n",
      "42 1165040\n",
      " no act data\n",
      "43 25349\n",
      "44 1234088\n",
      "45 827285\n",
      "46 FJ227MJ\n",
      "47 1124659\n",
      "48 1422927\n",
      "49 1270329\n",
      "50 1219403\n",
      "51 345921\n",
      "52 1367477\n",
      "53 1505268\n",
      "54 1579481\n",
      "55 HH880DL\n",
      "56 HE593LT\n",
      " no weather data\n",
      "57 WT253RB\n",
      "58 606449\n",
      "59 UQ050PR\n",
      " no weather data\n",
      "60 1549226\n",
      "61 1312819\n",
      "62 428255\n",
      " no act data\n",
      "63 1013558\n",
      "64 1425272\n",
      "65 1428949\n",
      " no act data\n",
      "66 1524947\n",
      "67 1533327\n",
      "68 1305690\n",
      "69 1084240\n",
      "70 831987\n",
      "71 1079411\n",
      "72 1496251\n",
      " no weather data\n",
      "73 1078563\n",
      " no act data\n",
      "74 872451\n",
      "75 QC647KS\n",
      " no act data\n",
      "76 249499\n",
      "77 828778\n",
      "78 1143410\n",
      "79 506107\n",
      " no act data\n",
      "80 616751\n",
      "81 1569370\n",
      "82 1503395\n",
      "83 1388630\n",
      "84 1145713\n",
      "85 1497026\n",
      "86 1444502\n",
      "87 820387\n",
      "88 1097633\n",
      "89 1128660\n",
      " no act data\n",
      "90 1147164\n",
      "91 856513\n",
      " no act data\n",
      "92 1041304\n",
      "93 1307868\n",
      "94 1189725\n",
      "95 920558\n",
      "96 62977\n",
      "97 1355344\n",
      " no act data\n",
      "98 575209\n",
      "99 1179075\n",
      "100 IQ300QN\n",
      "101 1272711\n",
      "102 1184498\n",
      "103 DB233EI\n",
      "104 1022235\n",
      "105 1299151\n",
      " no act data\n",
      "106 871322\n",
      "107 1560722\n",
      "108 433874\n",
      " no act data\n",
      "109 1557966\n",
      "110 906629\n",
      "111 636646\n",
      "112 1401878\n",
      "113 489868\n",
      "114 964685\n",
      "115 1336140\n",
      "116 1155329\n",
      "117 1567198\n",
      "118 560623\n",
      "119 98384\n",
      "120 TP903SN\n",
      "121 1213494\n",
      " no act data\n",
      "122 HU113HP\n",
      "123 1051651\n",
      "124 1495360\n",
      "125 97397\n",
      "126 1411525\n",
      "127 CB832WW\n",
      "128 QE210HJ\n",
      "129 1217425\n",
      "130 1213535\n",
      " no act data\n",
      "131 1057121\n",
      "132 510909\n",
      " no act data\n",
      "133 1370566\n",
      "134 NJ280ID\n",
      " no act data\n",
      "135 1537431\n",
      "136 1213906\n",
      "137 CP140WM\n",
      "138 1130163\n",
      "139 1294671\n",
      "140 1569348\n",
      "141 1002060\n",
      "142 1225160\n",
      "143 1328707\n",
      "144 HI713WB\n",
      "145 1150915\n",
      "146 1170978\n",
      "147 1255682\n",
      "148 564447\n",
      "149 1126979\n",
      "150 1307899\n",
      "151 1080326\n",
      "152 765488\n",
      "153 1027472\n",
      "154 1164303\n",
      "155 JK130XR\n",
      "156 662410\n",
      "157 AC363GY\n",
      "158 QG620BT\n",
      "159 1334243\n",
      "160 JS253NF\n",
      "161 1439160\n",
      "162 733021\n",
      "163 411896\n",
      "164 1495049\n",
      "165 1560782\n",
      "166 1523880\n",
      "167 1126438\n",
      "168 SP157RF\n",
      "169 555220\n",
      "170 BJ540PT\n",
      "171 1515656\n",
      "subject skipped due to spoofed gps data\n",
      "172 639010\n",
      "173 1380734\n",
      "174 391378\n",
      "175 1382086\n",
      " no act data\n",
      "176 1531633\n",
      "177 NQ003SV\n",
      "178 1207041\n",
      "179 1565499\n",
      "180 JB320SW\n",
      "181 1403756\n",
      "182 919141\n",
      "183 1550259\n",
      "184 106743\n",
      "185 1177977\n",
      "186 39468\n",
      "187 1199841\n",
      "188 913164\n",
      " no weather data\n",
      "189 1178484\n",
      "190 1148714\n",
      "191 1479464\n",
      "192 1553904\n",
      "193 630742\n",
      "194 1401811\n",
      "195 1433908\n",
      "196 1157796\n",
      "197 1229114\n",
      " no act data\n",
      "198 XU620RL\n",
      "199 1407619\n",
      "200 1409046\n",
      "201 1056017\n",
      "202 1230637\n",
      "203 38880\n",
      "204 1061128\n",
      "205 CL263NI\n",
      "206 1186533\n",
      "207 619634\n"
     ]
    }
   ],
   "source": [
    "# subjects = subjects[:2]\n",
    "\n",
    "ind_nan = np.where(np.isnan(timezones[1]))[0]\n",
    "timezones.loc[ind_nan,1]=0\n",
    "\n",
    "acts = []\n",
    "emas = []\n",
    "emss = []\n",
    "wtrs =[]\n",
    "subjects_edited = []\n",
    "\n",
    "for (cnt,subj) in enumerate(subjects):\n",
    "    \n",
    "    print(cnt,subj,)\n",
    "    \n",
    "    if subj=='1515656':\n",
    "        print('subject skipped due to spoofed gps data')\n",
    "        continue\n",
    "    \n",
    "    subjects_edited.append(subj)\n",
    "    \n",
    "    act = pd.DataFrame(columns=['date','act'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/act.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/act.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+ 3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        act['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(act['date']):\n",
    "             act.loc[i,'act'] = np.sum(data.loc[data[0]==da,1]=='BIKING')+np.sum(data.loc[data[0]==da,1]=='ON_FOOT')\n",
    "    else:\n",
    "        print(' no act data')\n",
    "    acts.append(act)\n",
    "\n",
    "    ema = pd.DataFrame(columns=['date','stress','mood','energy','focus'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/emm.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/emm.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+ 3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        ema['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(ema['date']):\n",
    "            ema.loc[i,'stress'] = np.nanmean(data.loc[data[0]==da,1])\n",
    "            moods = data.loc[data[0]==da,2]\n",
    "            ema.loc[i,'mood'] = np.nanmean(moods)\n",
    "            ema.loc[i,'energy'] = np.nanmean(data.loc[data[0]==da,3])\n",
    "            ema.loc[i,'focus'] = np.nanmean(data.loc[data[0]==da,4])\n",
    "    else:\n",
    "        print(' no ema data')\n",
    "    emas.append(ema)\n",
    "    \n",
    "    ems = pd.DataFrame(columns=['date','duration','quality','daytype'], dtype=float)\n",
    "    if os.path.exists(data_dir+subj+'/ems.csv'):\n",
    "        data = pd.read_csv(data_dir+subj+'/ems.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[3]/1000.0+3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        ems['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(ems['date']):\n",
    "            ems.loc[i,'duration'] = np.nanmean(data.loc[data[0]==da,3]-data.loc[data[0]==da,2])/1000.0\n",
    "            qual = np.array(data.loc[data[0]==da,5])\n",
    "            # if multiple entries, only take the first one\n",
    "            if qual.size>1:\n",
    "                ems.loc[i,'quality'] = qual[0]\n",
    "            else:\n",
    "                ems.loc[i,'quality'] = np.nanmean(qual)\n",
    "            daytype = data.loc[data[0]==da,6]\n",
    "            if daytype.size>0:\n",
    "                ems.loc[i,'daytype'] = daytype2number(daytype.values[0])\n",
    "            else:\n",
    "                ems.loc[i,'daytype'] = np.nan\n",
    "    else:\n",
    "        print(' no ems data')\n",
    "    emss.append(ems)\n",
    "        \n",
    "    wtr = pd.DataFrame(columns=['date','mean_temp','clear'], dtype=float)\n",
    "    if os.path.exists(weather_dir+subj+'/wtr.csv') and  os.stat(weather_dir+subj+'/wtr.csv').st_size > 0:\n",
    "        data = pd.read_csv(weather_dir+subj+'/wtr.csv',sep='\\t',header=None)\n",
    "        # convert timestamps to daystamps\n",
    "        data[0] = np.floor((data[0]+3600*float(timezones.loc[timezones[0]==subj,1]))/86400.0)\n",
    "        # loading into new matrix\n",
    "        wtr['date'] = np.arange(data.loc[0,0],data.loc[data.shape[0]-1,0])\n",
    "        for (i,da) in enumerate(wtr['date']):\n",
    "            # wrt.loc[i,'duration'] = np.nanmean(data.loc[data[0]==da,1])/1000.0\n",
    "            tmptemp = np.array(data.loc[data[0]==da,1])\n",
    "            tmpclear = np.array(data.loc[data[0]==da, 9])\n",
    "\n",
    "            # take the mean of multiple entries\n",
    "            if tmptemp.size>0:\n",
    "                wtr.loc[i,'mean_temp'] = np.nanmean(tmptemp)\n",
    "                wtr.loc[i, 'clear'] = np.sum(tmpclear=='Clear');\n",
    "    else:\n",
    "        print(' no weather data')\n",
    "    wtrs.append(wtr)\n",
    "    \n",
    "subjects = subjects_edited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for (i,_) in enumerate(subjects):\n",
    "    \n",
    "    a = pd.merge(emas[i],emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    a = pd.merge(a,wtrs[i], on='date', how='outer')\n",
    "    \n",
    "    # delayed (-1)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    acts[i]['date'] += 1\n",
    "    wtrs[i]['date'] += 1\n",
    "    emas[i].columns = ['date','stress_prev','mood_prev','energy_prev','focus_prev']\n",
    "    emss[i].columns = ['date','duration_prev','quality_prev','daytype_prev']\n",
    "    acts[i].columns = ['date','act_prev']\n",
    "    wtrs[i].columns = ['date','mean_temp_prev', 'clear_prev']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    a = pd.merge(a,wtrs[i], on='date', how='outer')\n",
    "\n",
    "    # removing extra columns\n",
    "    emss[i] = emss[i].drop(['duration_prev','daytype_prev'], axis=1)\n",
    "    \n",
    "    # delayed (-2)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    acts[i]['date'] += 1\n",
    "    wtrs[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev2','stress_prev2','energy_prev2','focus_prev2']\n",
    "    emss[i].columns = ['date','quality_prev2']\n",
    "    acts[i].columns = ['date','act_prev2']\n",
    "    wtrs[i].columns = ['date','mean_temp_prev2', 'clear_prev2']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "    a = pd.merge(a,acts[i],on='date',how='outer')\n",
    "    a = pd.merge(a,wtrs[i],on='date',how='outer')\n",
    "\n",
    "    # removing extra columns\n",
    "    emas[i] = emas[i].drop(['stress_prev2','energy_prev2','focus_prev2'], axis=1)\n",
    "    \n",
    "    # delayed (-3)\n",
    "    emas[i]['date'] += 1\n",
    "    emss[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev3']\n",
    "    emss[i].columns = ['date','quality_prev3']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    a = pd.merge(a,emss[i],on='date',how='outer')\n",
    "\n",
    "    # delayed (-4) - for mood only\n",
    "    emas[i]['date'] += 1\n",
    "    emas[i].columns = ['date','mood_prev4']\n",
    "    a = pd.merge(a,emas[i],on='date',how='outer')\n",
    "    \n",
    "    data.append(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add day of the week and save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import datetime as dt\n",
    "import calendar\n",
    "\n",
    "for (i,_) in enumerate(subjects):\n",
    "    ts =data[i].date*86400\n",
    "    #tmp =dt.datetime.fromtimestamp().day\n",
    "    data[i]['dow']=[dt.datetime.fromtimestamp(t).weekday() for t in ts]\n",
    "    \n",
    "with open('data.dat','wb') as f:\n",
    "    pickle.dump([data, subjects], f, protocol=2)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
